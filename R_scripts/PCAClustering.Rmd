---
title: "PCA_clustering290520.Rmd"
author: "rhodgson"
date: "29/05/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Perform PCA. How many principal components do you think you should keep for follow up analysis?
2. Use the experimental metadata to visualise which cell types cluster together.
3. Investigate which cell types (if any) the  rst few principal components are separating.
4. Find the top genes associated with PC1 and PC2. Visualise gene expression values by cell type.
5. Compare PCA to tSNE to UMAP.
6. How would you cluster the data? How many clusters would you choose?
7. Compare known cell type and cluster labels.

```{r}
#BiocManager::install("ExperimentHub")
```

```{r}
#BiocManager::install("SingleR")
```

ExperimentHub is a repository of publicably available datasets - only datasets available that have all the metadata available to allow testing of new methods. IE toy datasets
```{r}
library(ExperimentHub)
ehub <- ExperimentHub()
logcounts <- readRDS("/Users/rhodgson/OBDStestdata/Week5/eHUB/logcounts.rds")
col_data <- readRDS("/Users/rhodgson/OBDStestdata/Week5/eHUB/col_data.rds")
```
Did not use
```{r}
#logcounts <- ehub[["EH3094"]] # logcounts
#col_data <- ehub[["EH3095"]] # colData
```

#Perform PCA
Do on the logcounts file - center is true and scale is true
Perform PCA. How many principal components do you think you should keep for follow up analysis?

x contains the PCA matrix
PCs are columns and genes are the names

Genes as features as we want the genes to be column names and samples as rownmaes
Now for each sample, coordinate for PCs.
Reduced dimension for however many PCs to dimensions 

```{r}
PCA <- prcomp(t(logcounts), center=TRUE, scale = TRUE)
str(PCA)

PCA$x
dim(PCA$x)
```
#Screeplot to figure out how many PCs to use

```{r}
#BiocManager::install("factoextra")
```
Scree/Elbow plots to choose number of PCS
```{r}
library(factoextra)
fviz_eig(PCA, ncp=40)
```

get eigen value will give you variance in variance.percent
cumulate variance percent 
```{r}
Eigen <- as.data.frame(get_eigenvalue(PCA)) %>% mutate(PC=row_number())
colnames(Eigen)
ggplot(Eigen, aes(x=PC,y=cumulative.variance.percent))+geom_col(count=20)+geom_hline(yintercept = 95)
```

Manual way
screeplot gives absolute variance as default
```{r}
screeplot(PCA, npcs = min(50, length(PCA$sdev)),
          type = c("barplot", "lines"))
```

Adding in rest of library
```{r}
library(matrixStats)
library(tidyverse)
library(cowplot)
library(reshape2)
library(Rtsne)
```

#Kevin's way

Checking that the samples in logcoutns are present in metadata
```{r}
table(colnames(logcounts) %in% rownames(col_data))
```
Find most variable genes - variance of each row
```{r}
var_genes <- rowVars(logcounts)
var_genes

```
Find top most varied gene by ordering by vargenes (variance)
subset on keep_genes (top 1000)
```{r}
df_order <- tibble(variance=var_genes,
                   order(var_genes, decreasing = TRUE))
#take head(1000) values
keep_genes <- head(order(var_genes, decreasing = TRUE), 1000)
logcounts_subset<- logcounts[keep_genes, ]
dim(logcounts_subset)
head(logcounts_subset)
```
#PCA on top 1000 variable genes
weight of each gene on PC 

rotation #gives weight of each gene on PC
```{r}
prcomp_out <- prcomp(x=t(logcounts_subset))
str(prcomp_out)

View(prcomp_out$rotation)
View(prcomp_out$sdev) #gives stdev - vairance
rowSums((prcomp_out$rotation))
```


Visualise PC coloured by cell type
Pasting together with bind_cols()
Keeping track of sample name, main label (annotation of sample),

label.main gives cell type annotation (based on metadata)
tidyverse to reshape matrix. tissue annonation and PC1 and PC2


```{r}
plot_data <- bind_cols(
  sample = rownames(prcomp_out$x),
  label.main = col_data$label.main,
  prcomp_out$x %>% as_tibble() %>% dplyr::select(PC1, PC2)
)
```

Plot this by PC1 and PC2, colouring by the cell type metadata

```{r}
gg_pca <- plot_data %>% ggplot()+
  geom_point(aes(PC1, PC2, color=label.main))+
  theme_cowplot()
gg_pca
```
#Scree plot
capture standard deviation 
seqalong - captures info of PC for each PC throughout (gives a label for each PC- 1- however)
percentage of variance of each PC
cumsum gives you culmative variance - how much of variance is explained by 1, 2, 3 4 5 etc PCs
```{r}
scree_table <- tibble( sdev=prcomp_out$sdev,
                       PC=seq_along(prcomp_out$sdev),
                       percent_var=sdev^2/sum(sdev^2),
                       var_cumsum=cumsum(percent_var)
                       )
head(scree_table)
```
ggplotting a scree plot by PC number (defined above) with percent variance (also defined above)
```{r}
ggplot(head(scree_table, 50), aes(PC, percent_var))+
  geom_col(fill="grey")+
  geom_point()+
  scale_x_continuous(breaks=seq_along(scree_table$PC))+
  labs(y="%Variance explained", title = "Percentage of Variance explained ")+
  theme_cowplot()+
  theme(axis.text.x = element_text(size = rel(0.5)))
```
Plot cumsum 
```{r}
ggplot(head(scree_table, 50), aes(PC, var_cumsum))+
  geom_line()+
  geom_point()+
  geom_hline(yintercept = 0.9)+
  scale_x_continuous(breaks=seq_along(scree_table$PC))+
  labs(y="Cumulative %Variance explained", title = "Cumulative Percentage of Variance explained ")+
  theme_cowplot()+
  theme(axis.text.x = element_text(size = rel(0.5)))
```

#Identify top genes for a given PC
Remember that $rotation from the PCA output gives you weight of each gene on the PC. 
Help you identify which genes drive PC - higher weight, higher influence on the PC 
Matrix >> melt it 

so we can identify top 10 genes with top weight on PC1
Look at negative too as these will influence just as much - bit below this 
```{r}
prcomp_out$rotation[, "PC1"] %>%
  sort(decreasing = TRUE) %>% tail(10)
```

```{r}
prcomp_out$rotation %>% 
  melt(varnames = c("gene", "PC"), value.name = "loading") %>%
  as_tibble() %>%
  filter(PC == "PC1") %>%
  mutate(loading_abs = abs(loading)) %>%
  top_n(n=20, wt=loading_abs) %>%
  arrange(desc(loading_abs))
```
#Run tSNE
26 PCs handle most of the data variance
some samples are exact duplicates of each other, so tell to ignore duplicates
Running tSNE on output of matrix - first 1:25 columns
Seed could be any number so you initialise randomness, setting seed sets the randomness so you can same out

```{r}
set.seed(1)
tsne_out <- Rtsne(prcomp_out$x[, 1:25], 
                  check_duplicates = FALSE)
```

Visualise tSNE
```{r}
tsne_data <- as.data.frame(tsne_out$Y) 
#rownames(tsne_data)
plot(tsne_data) 
     #col=label.main)
```

ggplot
labels are from col_data$label.main
```{r}

#colnames(tsne_data) <- c("tSNE_1", "tSNE2")
colnames(tsne_data)
tsne_data$celltype <- col_data$label.main
ggplot(tsne_data, aes(x=V1, y=V2, col=celltype))+
  geom_point()
```

#Try UMAP for homework

#Now to cluster:
How would you cluster the data? How many clusters would you choose?
7. Compare known cell type and cluster labels.

```{r}
#if(!require(devtools)) install.packages("devtools")
#devtools::install_github("kassambara/factoextra")
#library(factoextra)
```

```{r}
#install.packages("dbscan")
library("dbscan")
```

Perplexity is like resolution really - all depends on what you want out, resoolution of the clusters etc
So what do we want to feed into dbscan scan?
Increase eps to increase clusters - relax how close points hae to be 
```{r}
dbscan2 <-dbscan(prcomp_out$x[,1:25], eps = 15, minPts =3)
#, scale = FALSE) 
       #method = c("hybrid", "raw", "dist"))
dbscan2
dbs <- as.data.frame(dbscan2$cluster)
plot(dbs)
```
Look at distance KNN plot
 distance to 10 nearest neighbour for each 
 
 KNN distance will give you input for dbscan function 
 value on y axis so each point has x neighbours
 
 
 The idea is to calculate, the average of the distances of every point to its k nearest neighbors. The value of k will be specified by the user and corresponds to MinPts.

Next, these k-distances are plotted in an ascending order. The aim is to determine the “knee”, which corresponds to the optimal eps parameter.

A knee corresponds to a threshold where a sharp change occurs along the k-distance curve.


dbscan tries to figure out how to turn into cluster
```{r}
kNNdistplot(x = prcomp_out$x[, 1:25])
#ggplot(tsne_data, aes(x=V1, y=V2, col=celltype))+
  #geom_point()
```

```{r}
#library(umap)
library(umap)
library(dbscan)

umap_out <- umap(prcomp_out$x[, 1:25])


library(dbscan)
kNNdistplot(x = umap_out$layout, k = 10)

dbscan_out <- dbscan(x = umap_out$layout, eps = 0.5, minPts = 5)
dbscan_out

umap_plot_table <- bind_cols(
  umap_out$layout %>% as_data_frame() %>% as_tibble(),
  dbscan_cluster = as.factor(dbscan_out$cluster)
)

ggplot(umap_plot_table, aes(V1, V2, color = dbscan_cluster)) +
  geom_point()
```
Plot clusters as theyved made it here

```{r}
umap_plot_table <- bind_cols(
  umap_out$layout %>% as_data_frame()
  %>% as_tibble(), dbscan_cluster =as.factor(dbscan_out$cluster))

ggplot(umap_plot_table, aes(V1, V2, color=dbscan_cluster))+
  geom_point()


```






Piyush's code 
```{r}
library("factoextra")
library("fpc")
#library("fviz_cluster")
set.seed(123)

 

data("multishapes", package = "factoextra")
df <- prcomp_out$x[,1:25]
db <- fpc::dbscan(prcomp_out$x[,1:25], eps = 15, MinPts = 5)
plot(db, df, main = "DBSCAN", frame = FALSE)

fviz_cluter(db, df, stand=FALSE, frame =FALSE, geom= "point")
```




```{r}
BiocManager::install("hdbscan")
library("hdbscan")
hdbscan <- HDBSCAN(min_samples=10, min_cluster_size=500)
y_predicted = hdbscan_instance.fit_predict(umap_transformed)
```

